FAQ: Document QnA System

Q: How much memory does the system use?
A: The system is designed to use less than 8GB RAM total, including the OS and other applications. The embeddings model (all-MiniLM-L6-v2) uses about 80MB, and phi3 uses approximately 2-3GB.

Q: Can I use my own documents?
A: Yes! The system supports PDF files, HTML files, Markdown documents, and plain text. You can also provide URLs to process web content.

Q: How accurate are the citations?
A: Citations include the source document name and page/section number when available. For PDFs, page numbers are extracted directly. For other formats, section numbers are used.

Q: Can I run this offline?
A: Absolutely! Once you have downloaded the required models (all-MiniLM-L6-v2 and phi3), the entire system runs locally without internet connectivity.

Q: What if I want to use different models?
A: The system is modular. You can swap the embedding provider (e.g., use OpenAI embeddings) or the LLM provider (e.g., use OpenAI GPT models) by modifying the configuration.

Q: How do I improve answer quality?
A: Try adjusting the chunk size, overlap, or top-k retrieval settings. Also ensure your questions are specific and relate to the content in your documents.
